{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pymorphy2\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import hstack, vstack\n",
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_columns', 80) \n",
    "pd.set_option('display.max_rows', 100) \n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"../data/avito/train.csv\", sep=';')\n",
    "data_test = pd.read_csv(\"../data/avito/test.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "min_data = datetime.datetime.strptime(data_train.start_time.min(),  \"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parse - приведение слов к нормальной форме с использованием pymorphy2\n",
    "\n",
    "get_time - количество секунд от минимальной даты в выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(x):\n",
    "    return ' '.join([morph.normal_forms(i)[0] for i in re.findall('\\w+', x)]) \n",
    "def rmse(x, y):\n",
    "    return np.sqrt(np.mean((x-y)**2))\n",
    "def get_time(x):\n",
    "    return (datetime.datetime.strptime(x,  \"%Y-%m-%d %H:%M:%S\") - min_data).total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing - предобработка данных. Заполняем nanы некоторой строкой. Категориальные кодируем label endcoderом. Ключевой признак сразу логарифмируем. Добавляем новые фичи: для каждого категориального признака ставим в соответствии каждому значению его частоту. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocessing(train, test):\n",
    "    \n",
    "    X = train.copy().fillna('na')\n",
    "    Xtest = test.copy().fillna('na')\n",
    "    \n",
    "    X.title = X.title.apply(parse)\n",
    "    Xtest.title = Xtest.title.apply(parse)\n",
    "    \n",
    "    X.start_time = X.start_time.apply(get_time)\n",
    "    Xtest.start_time = Xtest.start_time.apply(get_time)\n",
    "    \n",
    "    data = pd.concat([X, Xtest])\n",
    "    encoder = LabelEncoder()\n",
    "    for col in ['owner_type', 'category', 'subcategory', 'param1', 'param2', 'param3',  'region']:\n",
    "        encoder.fit(data[col])\n",
    "        X[col] = encoder.transform(X[col])\n",
    "        Xtest[col] = encoder.transform(Xtest[col])\n",
    "        \n",
    "    y = np.log(X.item_views + 1)\n",
    "    X = X.drop(['item_views', '\\ufeffid', 'item_id'], axis=1)\n",
    "    Xtest = Xtest.drop(['\\ufeffid', 'item_id'], axis=1)\n",
    "    \n",
    "    data = pd.concat([X, Xtest])\n",
    "    for col in X.columns[1:]:\n",
    "        col_map = data.groupby(col).apply(len)\n",
    "        X['frequence_' + col] = X[col].map(col_map)\n",
    "        Xtest['frequence_' + col] = Xtest[col].map(col_map)\n",
    "\n",
    "    return X, Xtest, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 55s, sys: 1.71 s, total: 10min 56s\n",
      "Wall time: 10min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, Xtest, y = preprocessing(data_train, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем на выборку для обучения и валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.2, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для категориального признака важен порядок, с которым мы обозначаем категории числами. Иногда полезно делать так, чтобы порядок выбирался в соответствии со средним значением ключевого признака внутри каждой категории. Важно, что можно использовать только таргеты из обучающей выборки, поэтому если категорий много или количество объектов внутри категории мало (то есть если средние значение внутри категории не стабильно), то это приведет к переобучению. И наоборот, если категорий мало, то это просто ничего не изменит. В данном случае полезно было переобозначить категории признака param1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_map = ytrain.groupby(Xtrain.param1).mean()\n",
    "Xtrain['y'] = Xtrain.param1.map(y_map)\n",
    "Xval['y'] = Xval.param1.map(y_map).fillna(ytrain.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление шумовых объектов.\n",
    "\n",
    "Делаем кросс-валидацию. Для каждого разбиения X1, X2 строим модель на X1, прогнозируем на X2, смотрим ошибку. В итоге для каждого объекта есть ошибка. Удаляем объекты, ошибка на которых больше некоторого порога."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = KFold(len(Xtrain), n_folds=5, random_state=241, shuffle=True)\n",
    "p = pd.Series(index=Xtrain.index)\n",
    "model = xgboost.XGBRegressor(n_estimators=800, max_depth=8, seed=241)\n",
    "for train, test in cv:\n",
    "    X1 = Xtrain.iloc[train].drop('title', axis=1)\n",
    "    X2 = Xtrain.iloc[test].drop('title', axis=1)\n",
    "    y1 = ytrain.iloc[train]\n",
    "    model.fit(X1, y1)\n",
    "    p.iloc[test] = model.predict(X2)\n",
    "index = abs(p - ytrain) < 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain = Xtrain[index]\n",
    "ytrain = ytrain[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берем 5000 наиболее популярных слов из title. Делаем 5000 бинарных признаков - есть ли данное слово в title. Очень удобно делать с использованием CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=5000, binary=True)\n",
    "vectorizer.fit(pd.concat([Xtrain, Xval]).title)\n",
    "title1 = vectorizer.transform(Xtrain.title)\n",
    "title2 = vectorizer.transform(Xval.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain2 = hstack([Xtrain.drop('title', axis=1), title1])\n",
    "Xval2 = hstack([Xval.drop('title', axis=1), title2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Три хгбуста с разной глубиной деревьев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1 = xgboost.XGBRegressor(n_estimators=5627, \n",
    "                              max_depth=10, \n",
    "                              subsample=0.9, \n",
    "                              colsample_bytree=0.8, \n",
    "                              reg_lambda=0, \n",
    "                              reg_alpha=2, \n",
    "                              learning_rate=0.05, \n",
    "                              seed=250)\n",
    "\n",
    "model2 = xgboost.XGBRegressor(n_estimators=4511, \n",
    "                              max_depth=12, \n",
    "                              subsample=0.9, \n",
    "                              colsample_bytree=0.8, \n",
    "                              reg_lambda=0, \n",
    "                              reg_alpha=2, \n",
    "                              learning_rate=0.05, \n",
    "                              seed=200)\n",
    "\n",
    "\n",
    "model3 = xgboost.XGBRegressor(n_estimators=1627, \n",
    "                              max_depth=20, \n",
    "                              subsample=0.9, \n",
    "                              colsample_bytree=0.8, \n",
    "                              reg_lambda=0, \n",
    "                              reg_alpha=2, \n",
    "                              learning_rate=0.05, \n",
    "                              seed=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем, смотрим скор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6h 15min 20s, sys: 8min 35s, total: 6h 23min 55s\n",
      "Wall time: 1h 13min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model1.fit(Xtrain2, ytrain)\n",
    "model2.fit(Xtrain2, ytrain)\n",
    "model3.fit(Xtrain2, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p1 = model1.predict(Xval2)\n",
    "p2 = model2.predict(Xval2)\n",
    "p3 = model3.predict(Xval2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5459918192097577,\n",
       " 0.54581715413917054,\n",
       " 0.54674203841925728,\n",
       " 0.54825069853687303)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(yval, p1), rmse(yval, p2), rmse(yval, p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбираем коэффициенты блендинга:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54392735884533139"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([5, 4, 4])\n",
    "a = a / a.sum()\n",
    "rmse(yval, a.dot([p1, p2, p3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Проделываем ту же работу уже для финального X, Xtest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_map = y.groupby(X.param1).mean()\n",
    "X['y'] = X.param1.map(y_map)\n",
    "Xtest['y'] = Xtest.param1.map(y_map).fillna(y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46min 49s, sys: 58.1 s, total: 47min 47s\n",
      "Wall time: 8min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = KFold(len(X), n_folds=5, random_state=241, shuffle=True)\n",
    "p = pd.Series(index=X.index)\n",
    "model = xgboost.XGBRegressor(n_estimators=800, max_depth=8, seed=241)\n",
    "for train, test in cv:\n",
    "    X1 = X.iloc[train].drop('title', axis=1)\n",
    "    X2 = X.iloc[test].drop('title', axis=1)\n",
    "    y1 = y.iloc[train]\n",
    "    model.fit(X1, y1)\n",
    "    p.iloc[test] = model.predict(X2)\n",
    "index = abs(p - y) < 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X[index]\n",
    "y = y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer.fit(pd.concat([X, Xtest]).title)\n",
    "title1 = vectorizer.transform(X.title)\n",
    "title2 = vectorizer.transform(Xtest.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = hstack([X.drop('title', axis=1), title1])\n",
    "Xtest = hstack([Xtest.drop('title', axis=1), title2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5h 26min 41s, sys: 6min 7s, total: 5h 32min 48s\n",
      "Wall time: 1h 5min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model1.fit(X, y)\n",
    "model2.fit(X, y)\n",
    "model3.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1test = model1.predict(Xtest)\n",
    "p2test = model2.predict(Xtest)\n",
    "p3test = model3.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ptest = a.dot([p1test, p2test, p3test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer = np.e** ptest - 1\n",
    "sub = pd.DataFrame(answer).reset_index()\n",
    "sub.columns = ['id', 'item_views']\n",
    "sub.to_csv('C.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Говорят, можно обучить модель на трейне и на тесте, используя предсказания на тесте и тем самым немного улучшить результат. В данной задаче не прокатило, да и вообще для задачи регрессии это кажется дико. Но код оставил."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11h 55min 17s, sys: 7min 24s, total: 12h 2min 42s\n",
      "Wall time: 2h 24min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model1.fit(vstack([X, Xtest]), np.hstack([y, p1test]))\n",
    "model2.fit(vstack([X, Xtest]), np.hstack([y, p2test]))\n",
    "model3.fit(vstack([X, Xtest]), np.hstack([y, p3test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p1test_ = model1.predict(Xtest)\n",
    "p2test_ = model2.predict(Xtest)\n",
    "p3test_ = model3.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ptest_ = a.dot([p1test_, p2test_, p3test_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer = np.e** ptest_ - 1\n",
    "sub = pd.DataFrame(answer).reset_index()\n",
    "sub.columns = ['id', 'item_views']\n",
    "sub.to_csv('C2.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
